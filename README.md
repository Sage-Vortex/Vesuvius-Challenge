# Vesuvius Surface Detection â€“ 3D Scroll Segmentation

**It is essential to note that since the competition was to be submitted offline, I had to add datasets for Segmentation via Pytorch and a trained model with ResNet weights.**

### vesuvius_LightTraining.py
This repository contains a streamlined implementation of a surface detection pipeline for the Vesuvius Challenge dataset using volumetric scroll scans. The model performs voxel-level semantic segmentation by treating stacked z-slices as multi-channel inputs and training a U-Net architecture with a ResNet34 encoder adapted for 16-channel volumetric data. Large TIFF volumes are divided into overlapping patches using a sliding-window strategy to enable training and inference within GPU memory limits. The pipeline includes percentile-based normalization, simple spatial augmentations, mixed-precision training, and weighted cross-entropy loss to compensate for heavy class imbalance between air, surface, and interior regions.

Compared to the later full pipeline version, this implementation intentionally reduces computational complexity and training scope to enable faster experimentation and lower resource usage. Only a small subset of training volumes is used, fewer epochs are performed, and thresholding during inference is fixed rather than optimized through validation-based tuning. While this makes the workflow quicker to run and easier to iterate on, it also results in weaker generalization and less stable segmentation quality. The absence of dataset aggregation, reduced training duration, and simplified evaluation steps mean the model serves primarily as a lightweight baseline or debugging pipeline rather than a fully optimized solution. In short, this version trades accuracy and methodological rigor for speed and simplicity, making it useful for rapid prototyping but objectively less robust than the previous, more comprehensive training pipeline.

### vesuvius_surface_segmentation.py
**Though this notebook did not give a score as 'Notebook Threw Exception' but this was in the best model I could have designed in the limited time.**
This project implements a deep learning pipeline for detecting surface regions within volumetric scroll data from the Vesuvius Challenge dataset. The system trains a 3D-aware segmentation model using stacked z-slices as multi-channel inputs and applies a U-Net architecture with a pretrained ResNet34 encoder adapted for volumetric data. Large TIFF volumes are processed using a sliding-window tiling strategy that enables training and inference on high-resolution scans within GPU memory constraints. The pipeline includes percentile-based normalization, data augmentation through spatial flipping, class-weighted loss to address severe label imbalance, and mixed-precision training for efficient GPU utilization.

During inference, the model predicts voxel-level probabilities across entire volumes by aggregating overlapping patch predictions, producing a smooth probability map for surface detection. A threshold optimization step selects the best binary segmentation cutoff using F1-score evaluation against known labels, after which predictions are generated for test volumes and exported as compressed TIFF masks packaged into a competition-ready submission file. The workflow is designed to be reproducible in offline Kaggle environments and demonstrates an end-to-end approach to large-scale 3D semantic segmentation, combining efficient data handling, pretrained feature extraction, and sliding-window reconstruction for volumetric analysis tasks.



